# 大数据
海量数据处理的唯一宗旨是解决如何更高效得处理数据。
内存、时间在海量数据大背景下显得格外显眼。
常见的处理方法有：分治思想、位图法
参考博客：https://segmentfault.com/a/1190000021109127
配套使用位图法漫画版食用极佳：https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg

## 大量数据下的高频词
题目描述：
有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。

简单思路：
首先遍历大文件，对遍历到的每个词x，执行 hash(x) % 5000，将结果为 i 的词存放到文件 ai 中。遍历结束后，我们可以得到 5000 个小文件。每个小文件的大小为 200KB 左右。**如果有的小文件大小仍然超过 1MB，则采用同样的方式继续进行分解。**

接着统计每个小文件中出现频数最高的 100 个词。最简单的方式是使用 HashMap 来实现。其中 key 为词，value 为该词出现的频率。

在对所有小文件求值结束后，采用**小顶堆**维护Top100即可。

点评：
1. 分治思想，这题是 mapreduce 的典型应用。
2. Top-K问题都是采用堆来维护，堆的一个好处是它可以维护流数据，是一个动态的过程。
3. 对于某一个文件仍然超过 1MB，这种情况就属于数据倾斜问题，需要特殊解决。
   
## 数据倾斜问题
问题的产生：
数据倾斜主要是由于 map 的过程某几个 key 的分布非常得多，以至于处理这几个 key 的 reduce 任务非常得慢，其他任务都完成了只是等待这几个 reduce 任务。

解决方法：
1. 处理极端 key，将其添加随机数后再哈希。
2. 设置 reduce 数量，让短作业多做任务。

## 大量数据找出不重复整数
题目描述：
在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。

简单思路：
- 分治

- 位图法。
  假设 int 整数占用 4B，即 32bit，那么一共有 2^32 个整数。对于这题我们用两个 bit 来表示各个数字的状态：

  - 00 表示这个数字没出现过；
  - 01 表示这个数字出现过一次（即为题目所找的不重复整数）；
  - 10 表示这个数字出现了多次。

  那么这 232 个整数，总共所需内存为 232*2b=1GB。因此，当可用内存超过 1GB 时，可以采用位图法。

点评：

1. 判断数字是否重复、是否出现过，非常适合位图法。
2. 假如说数据非常得稀疏，就会浪费很多空间，该怎么办呢？



## Bitmap 缺点

- 数据碰撞。比如将字符串映射到 BitMap 的时候会有碰撞的问题，那就可以考虑用 Bloom Filter 来解决，Bloom Filter 使用多个 Hash 函数来减少冲突的概率。
- 数据稀疏。又比如要存入(10,8887983,93452134)这三个数据，我们需要建立一个 99999999 长度的 BitMap ，但是实际上只存了3个数据，这时候就有很大的空间浪费，碰到这种问题的话，可以通过引入 Roaring BitMap 来解决。

对于稀疏数据，可以结合压缩或者序列化中的 Header 思想，在 Header 结点中维护该结点之前及之后已经分配的 bitmap 空间，这就好比邻接矩阵转化为邻接表一个道理。基于这种存储方式，就不适合在中间插入元素使得 Header 结点发生改变，这是不建议的，这就好比 mysql 中以主键自增的形式插入数据，减少页分裂的可能性。最后要知道 bitmap 扩容的思想，这其实跟 vector 扩容类似，选择倍数增长，而不是线性增长(*这个使用平均插入时间复杂度来证明即可。)



## Bitmap 在 SQL 中的应用

假如需要维护用户的标签信息，原本是一个标签对应数据库一个字段，这样来实现。

那么随着标签数量的增长，数据库字段迅速扩张，维护成本极高，查询数据效率极低。



如果使用 bitmap，转换一个思维方式，原本是一个用户对应m个标签，现在我们让一个标签对应n个用户。

对用户进行编号，存入 bitmap 中，这样我们就得到了 00001100B、 00000100B 这样的各种标签，在做 SQL 查询的时候可以使用位运算来实现，效率非常高。但是，值得注意的是，bitmap 是不支持**非运算**的，如果要实现这样的功能，需要我们额外维护一个全量 bitmap。