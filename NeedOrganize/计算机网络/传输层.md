# TCP协议

TCP协议全称: 传输控制协议，顾名思义，就是要对数据的传输进行一定的控制。

## 报头

![20180620002403691](D:\notes\面试准备\计算机网络\传输层.assets\20180620002403691.png)

* 源端口号/目的端口号：表示数据从哪个进程来，到哪个进程去。

  常用端口号：

  | 应用程序 | FTP  | TELNET | SMTP | DNS  | TFTP | HTTP | HTTPS | SNMP |
  | -------- | ---- | ------ | ---- | ---- | ---- | ---- | ----- | ---- |
  | 端口号   | 21   | 23     | 25   | 53   | 69   | 80   | 443   | 161  |

* 32位序号：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

* 32位确认序号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决不丢包的问题。**

* 4位首部长度：表示该TCP报头有多少个4字节（32个bit）。

* 6位保留：顾名思义，先保留着。

* 6位标志位
  
  * URG: 标识紧急指针是否有效
  * ACK: 该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
  * PSH: 用来提示接收端应用程序立刻将数据从tcp缓冲区读走
  * RST: 该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
  * SYN: 该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
  * FIN: 该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位置为 1 的 TCP 段。
  
* 16位窗口大小。

* 16位检验和：由发送端填充，检验形式由CRC校验等。如果接收端校验不通过，则认为数据有问题。此处的校验不光包括TCP首部，也包括TCP数据部分。

* 16位紧急指针：用来标识哪部分数据是紧急数据。

* 选项和数据暂时忽略。

## 什么是TCP？

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

![img](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeo9xBVAyPJ8iaWCC6sYS8438HibyWCtJ5Tn9VN7YuzgAibg46Ocdf7swUxgeKMQ9ge8Nic3WOibTSxPXA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；
- **字节流**：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节已经收到，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。

特征：

- 面向连接
- 只能点对点（一对一）通信
- 可靠交互
- 全双工通信
- 面向字节流

TCP 如何保证可靠传输：

- 确认和超时重传
- 数据合理分片和排序
- 流量控制
- 拥塞控制
- 数据校验

## 有一个IP的服务器监听了一个端口，它的TCP的最大连接数是多少？

服务器通常固定在某个本地端口上监听，等待客户端的连接请求。

因此，客户端 IP 和 端口是可变的，其理论值计算公式如下:

$最大TCP连接数=客户端的IP数 \times 客户端的端口数$

对 IPv4，客户端的 IP 数最多为 `2` 的 `32` 次方，客户端的端口数最多为 `2` 的 `16`次方，也就是服务端单机最大 TCP 连接数，约为 `2` 的 `48` 次方。

当然，服务端最大并发 TCP 连接数远不能达到理论上限。

- 首先主要是**文件描述符限制**，Socket 都是文件，所以首先要通过 `ulimit` 配置文件描述符的数目；
- 另一个是**内存限制**，每个 TCP 连接都要占用一定内存，操作系统是有限的。

## TCP的三次握手、四次挥手

下面两图大家再熟悉不过了，TCP 的三次握手和四次挥手见下面左边的”TCP 建立连接”、”TCP 数据传送”、”TCP 断开连接”时序图和右边的”TCP 协议状态机” 。

![v2-f2b18713052778a6c5aafc5e969f62a7_720w](D:\notes\面试准备\计算机网络\传输层.assets\v2-f2b18713052778a6c5aafc5e969f62a7_720w.jpg)

> seq：序列号
> ack：确认号

三次握手：

1. 客户端 A：发送 SYN 连接报文，序列号为 x，进入 SYNC-SENT 状态。
2. 服务端 B：发送 SYN 连接确认报文（SYN=1，ACK = 1），序列号为 y（seq = y），确认报文x（ack = x + 1），进入 SYNC-RCVD 状态。
3. 客户端 A：发送 ACK 确认报文（ACK = 1），序列号为 x+1（seq = x + 1），确认报文 y+1（ack = y + 1），进入 ESTABLISHED 状态。服务器 B：收到后进入 ESTABLISHED 状态。

> C-> SYN -> S
> S->SYN/ACK->C
> C->ACK->S
>
> * 一开始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态
>
> * 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。
>
>   ![640](D:\notes\面试准备\计算机网络\传输层.assets\640.png)
>
> * 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。
>
>   ![640](D:\notes\面试准备\计算机网络\传输层.assets\640.webp)
>
> * 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 `ESTABLISHED` 状态。
>
>   ![640 (1)](D:\notes\面试准备\计算机网络\传输层.assets\640 (1).webp)
>
> * 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。
>
> **如何在 Linux 系统中查看 TCP 状态？**
>
> TCP 的连接状态查看，在 Linux 可以通过 `netstat -napt` 命令查看。
>
> ![640 (2)](D:\notes\面试准备\计算机网络\传输层.assets\640 (2).webp)
>
> 

四次挥手：

1. 数据传输结束后，客户端的应用进程发出连接释放报文段，并停止发送数据，客户端进入FIN_WAIT_1 状态，此时客户端依然可以接收服务器发送来的数据。
2. 服务器接收到 FIN 后，发送一个 ACK 给客户端，确认序号为收到的序号+1，服务器进入CLOSE_WAIT 状态。客户端收到后进入 FIN_WAIT_2 状态。
3. 当服务器没有数据要发送时，服务器发送一个 FIN 报文，此时服务器进入 LAST_ACK 状态，等待客户端的确认。
4. 客户端收到服务器的 FIN 报文后，给服务器发送一个 ACK 报文，确认序列号为收到的序号+1。此时客户端进入 TIME_WAIT 状态，等待 2MSL（MSL：报文段最大生存时间），然后关闭连接。服务器端只要收到了客户端发出的确认，立即进入CLOSED状态。

> C->FIN->S
> S->ACK->C
> S->FIN->C
> C->ACK->S
>
> - 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
> - 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。
> - 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
> - 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
> - 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
> - 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
> - 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。
>
> 这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

### 原因

* 三次握手的原因：
  三次握手可以防止已经失效的连接请求报文突然又传输到服务器端导致的服务器资源浪费。例如，客户端先发送了一个 SYN，但是由于网络阻塞，该 SYN 数据包在某个节点长期滞留。然后客户端又重传 SYN 数据包并正确建立 TCP 连接，然后传输完数据后关闭该连接。该连接释放后失效的 SYN 数据包才到达服务器端。在二次握手的前提下，服务器端会认为这是客户端发起的又一次请求，然后发送 SYN ，并且在服务器端创建 socket 套接字，一直等待客户端发送数据。但是由于客户端并没有发起新的请求，所以会丢弃服务端的 SYN 。此时服务器会一直等待客户端发送数据从而造成资源浪费。

  1. **避免历史连接**

     简单来说，三次握手的**首要原因是为了防止旧的重复连接初始化造成混乱。**

     网络环境是错综复杂的，往往并不是如我们期望的一样，先发送的数据包，就先到达目标主机，反而它很骚，可能会由于网络拥堵等乱七八糟的原因，会使得旧的数据包，先到达目标主机，那么这种情况下 TCP 三次握手是如何避免的呢？

     ![640 (3)](D:\notes\面试准备\计算机网络\传输层.assets\640 (3).webp)

     客户端连续发送多次 SYN 建立连接的报文，在网络拥堵等情况下：

     - 一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端；
     - 那么此时服务端就会回一个 `SYN + ACK` 报文给客户端；
     - 客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 `RST` 报文给服务端，表示中止这一次连接。

     如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接：

     - 如果是历史连接（序列号过期或超时），则第三次握手发送的报文是 `RST` 报文，以此中止历史连接；
     - 如果不是历史连接，则第三次发送的报文是 `ACK` 报文，通信双方就会成功建立连接；

  2. **同步双方初始序列号**

     TCP 协议的通信双方，都必须维护一个「序列号」，序列号是可靠传输的一个关键因素，它的作用：

     - 接收方可以去除重复的数据；
     - 接收方可以根据数据包的序列号按序接收；
     - 可以标识发送出去的数据包中， 哪些是已经被对方收到的；

     可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 `SYN` 报文的时候，需要服务端回一个 `ACK` 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**

     ![640 (4)](D:\notes\面试准备\计算机网络\传输层.assets\640 (4).webp)

     四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了「三次握手」。

     而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

  3. **避免资源浪费**

     如果只有「两次握手」，当客户端的 `SYN` 请求连接在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 `ACK` 确认信号，所以每收到一个 `SYN` 就只能先主动建立一个连接，这会造成什么情况呢？

     如果客户端的 `SYN` 阻塞了，重复发送多次 `SYN` 报文，那么服务器在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

     ![640 (5)](D:\notes\面试准备\计算机网络\传输层.assets\640 (5).webp)

     即两次握手会造成消息滞留情况下，服务器重复接受无用的连接请求 `SYN` 报文，而造成重复分配资源。

> 请问 tcp 握手为两次不可以？为什么不用四次？
> 两次不可以：tcp 是全双工通信，两次握手只能确定单向数据链路是可以通信的，并不能保证反向的通信正常
> 不用四次：
> 本来握手应该和挥手一样都是需要确认两个方向都能联通的，本来模型应该是：
> 1.客户端发送 syn0 给服务器
> 2.服务器收到 syn0，回复 ack(syn0+1)
> 3.服务器发送 syn1
> 4.客户端收到 syn1，回复 ack(syn1+1)
> 因为 tcp 是全双工的，上边的四步确认了数据在两个方向上都是可以正确到达的，但是 2，3 步没有没有上下的联系，可以将其合并，加快握手效率，所有就变成了 3 步握手。

* 为什么客户端和服务端的初始序列号 ISN 是不相同的？
  
  因为网络中的报文**会延迟、会复制重发、也有可能丢失**，这样会造成的不同连接之间产生互相影响，所以为了避免互相影响，客户端和服务端的初始序列号是随机且不同的。
  
* 什么是 SYN 攻击？

  我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的 SYN 接收队列（未连接队列）**，使得服务器不能为正常用户服务。

  ![640 (7)](D:\notes\面试准备\计算机网络\传输层.assets\640 (7).webp)

* 四次挥手的原因：
  
  再来回顾下四次挥手双方发 `FIN` 包的过程，就能理解为什么需要四次了。
  
  - 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
  - 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。
  
  从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。
* 为什么TIME_WAIT等待的时间是2*MSL呢？

  `MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

  MSL 与 TTL 的区别：MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

  TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是：网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。

  比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 Fin 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。

  `2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。

  在 Linux 系统里 `2MSL` 默认是 `60` 秒，那么一个 `MSL` 也就是 `30` 秒。**Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒**。

  1. 保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。

     > A并不知道B是否接到自己的ACK，A是这么想的：
     >
     > 1）如果B没有收到自己的ACK，会超时重传FiN
     >
     > 那么A再次接到重传的FIN，会再次发送ACK
     >
     > 2）如果B收到自己的ACK，也不会再发任何消息，包括ACK
     >
     > 无论是1还是2，A都需要等待，要取这两种情况等待时间的最大值，**以应对最坏的情况发生**，这个最坏情况是：
     >
     > 去向ACK消息最大存活时间（MSL) + 来向FIN消息的最大存活时间(MSL)。
     >
     > 这恰恰就是**2MSL( Maximum Segment Life)。**

  2. 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。

* 为什么需要TIME_WAIT状态？

  主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。

  需要 TIME-WAIT 状态，主要是两个原因：

  - 防止具有相同「四元组」的「旧」数据包被收到；
  - 保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；

  *原因一：防止旧连接的数据包*

  假设 TIME-WAIT 没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？

  ![640 (9)](D:\notes\面试准备\计算机网络\传输层.assets\640 (9).webp)

  - 如上图黄色框框服务端在关闭连接之前发送的 `SEQ = 301` 报文，被网络延迟了。
  - 这时有相同端口的 TCP 连接被复用后，被延迟的 `SEQ = 301` 抵达了客户端，那么客户端是有可能正常接收这个过期的报文，这就会产生数据错乱等严重的问题。

  所以，TCP 就设计出了这么一个机制，经过 `2MSL` 这个时间，**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

  *原因二：保证连接正确关闭*

  TIME-WAIT 作用是**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**

  假设 TIME-WAIT 没有等待时间或时间过短，断开连接会造成什么问题呢？

  ![640 (10)](D:\notes\面试准备\计算机网络\传输层.assets\640 (10).webp)

  - 如上图红色框框客户端四次挥手的最后一个 `ACK` 报文如果在网络中被丢失了，此时如果客户端 `TIME-WAIT` 过短或没有，则就直接进入了 `CLOSE` 状态了，那么服务端则会一直处在 `LASE-ACK` 状态。
  - 当客户端发起建立连接的 `SYN` 请求报文后，服务端会发送 `RST` 报文给客户端，连接建立的过程就会被终止。

  如果 TIME-WAIT 等待足够长的情况就会遇到两种情况：

  - 服务端正常收到四次挥手的最后一个 `ACK` 报文，则服务端正常关闭连接。
  - 服务端没有收到四次挥手的最后一个 `ACK` 报文时，则会重发 `FIN` 关闭连接报文并等待新的 `ACK` 报文。

  所以客户端在 `TIME-WAIT` 状态等待 `2MSL` 时间后，就可以**保证双方的连接都可以正常的关闭。**

* 如果已经建立了连接，但是客户端突发故障了怎么办？

  TCP设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

## TCP可靠传输

### 重传机制

TCP 实现可靠传输的方式之一，是通过序列号与确认应答。

> **确认应答机制（ACK机制）**
>
> ![20180620002614358](D:\notes\面试准备\计算机网络\传输层.assets\20180620002614358.png)
>
> TCP将每个字节的数据都进行了编号，即为序列号。
>
> ![20180620002626330](D:\notes\面试准备\计算机网络\传输层.assets\20180620002626330.png)
>
> 每一个ACK都带有对应的确认序列号，意思是告诉发送者，我已经收到了哪些数据；下一次你要从哪里开始发。
> 比如，客户端向服务器发送了1005字节的数据，服务器返回给客户端的确认序号是1003，那么说明服务器只收到了1-1002的数据。1003，1004，1005都没收到。此时客户端就会从1003开始重发。

在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。

但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？

所以 TCP 针对数据包丢失的情况，会用**重传机制**解决。

#### 超时重传

重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，也就是我们常说的**超时重传**。

TCP 会在以下两种情况发生超时重传：

- 数据包丢失
- 确认应答丢失

![640 (11)](D:\notes\面试准备\计算机网络\传输层.assets\640 (11).webp)

#### 快速重传

TCP 还有另外一种**快速重传（Fast Retransmit）机制**，它**不以时间为驱动，而是以数据驱动重传**。

快速重传机制，是如何工作的呢？其实很简单，一图胜千言。

![640 (1)](D:\notes\面试准备\计算机网络\传输层.assets\640 (1).png)

在上图，发送方发出了 1，2，3，4，5 份数据：

- 第一份 Seq1 先送到了，于是就 Ack 回 2；
- 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；
- 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；
- **发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。**
- 最后，接收到收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。

所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是**重传的时候，是重传之前的一个，还是重传所有的问题。**

比如对于上面的例子，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2  是谁传回来的。

根据 TCP 不同的实现，以上两种情况都是有可能的。可见，这是一把双刃剑。

为了解决不知道该重传哪些 TCP 报文，于是就有 `SACK` 方法。

#### SACK方法

还有一种实现重传机制的方式叫：`SACK`（ Selective Acknowledgment 选择性确认）。

这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重传。

![640 (2)](D:\notes\面试准备\计算机网络\传输层.assets\640 (2).png)

如果要支持 `SACK`，必须双方都要支持。在 Linux 下，可以通过 `net.ipv4.tcp_sack` 参数打开这个功能（Linux 2.4 后默认打开）。

#### Duplicate SACK

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

下面举例两个栗子，来说明 `D-SACK` 的作用。

*栗子一号：ACK 丢包*

![640 (3)](D:\notes\面试准备\计算机网络\传输层.assets\640 (3).png)

- 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
- **于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500**，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 `D-SACK`。
- 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。

*栗子二号：网络延时*

![640 (4)](D:\notes\面试准备\计算机网络\传输层.assets\640 (4).png)

- 数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。
- 而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；
- **所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。**
- 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。

可见，`D-SACK` 有这么几个好处：

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

在 Linux 下可以通过 `net.ipv4.tcp_dsack` 参数开启/关闭这个功能（Linux 2.4 后默认打开）。

>**超时重传机制**
>
>![20180620002645335](D:\notes\面试准备\计算机网络\传输层.assets\20180620002645335.png)
>
>主机A发送数据给B之后，可能因为网络拥堵等原因，数据无法到达主机B。
>如果主机A在一个特定时间间隔内没有收到B发来的确认应答，就会进行重发。
>但是主机A没收到确认应答也可能是ACK丢失了。
>
>![20180620002717106](D:\notes\面试准备\计算机网络\传输层.assets\20180620002717106.png)
>
>这种情况下，主机B会收到很多重复数据。
>那么TCP协议需要识别出哪些包是重复的，并且把重复的丢弃。
>这时候利用前面提到的序列号，就可以很容易做到去重。
>
>**超时时间如何确定?**
>最理想的情况下，找到一个最小的时间，保证“确认应答一定能在这个时间内返回”。
>但是这个时间的长短，随着网络环境的不同，是有差异的。
>如果超时时间设的太长，会影响整体的重传效率；如果超时时间设的太短，有可能会频繁发送重复的包。
>
>TCP为了保证任何环境下都能保持较高性能的通信，因此会**动态计算**这个最大超时时间。
>
>Linux中(BSD Unix和Windows也是如此)，超时以`500ms`为一个单位进行控制，每次判定超时重发的超时时间都是`500ms`的整数倍。
>如果重发一次之后，仍然得不到应答，等待`2*500ms`后再进行重传。如果仍然得不到应答，等待`4*500ms`进行重传。
>依次类推，以指数形式递增。累计到一定的重传次数，TCP认为网络异常或者对端主机出现异常，强制关闭连接。

### 滑动窗口

#### 引入窗口概念的原因

我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。

这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是效率比较低的。

所以，这样的传输方式有一个缺点：数据包的**往返时间越长，通信的效率就越低**。

为解决这个问题，TCP 引入了**窗口**这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。

那么有了窗口，就可以指定窗口大小，窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

假设窗口大小为 `3` 个 TCP 段，那么发送方就可以「连续发送」 `3` 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。如下图：

![640 (12)](D:\notes\面试准备\计算机网络\传输层.assets\640 (12).webp)

图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通话下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫**累计确认**或者**累计应答**。

#### 窗口大小由哪一方决定？

TCP 头里有一个字段叫 `Window`，也就是窗口大小。

**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

所以，通常窗口的大小是由接收方的决定的。

发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

#### 发送方的滑动窗口

我们先来看看发送方的窗口，下图就是发送方缓存的数据，根据处理的情况分成四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口：

![640 (5)](D:\notes\面试准备\计算机网络\传输层.assets\640 (5).png)

- \#1 是已发送并收到 ACK确认的数据：1~31 字节
- \#2 是已发送但未收到 ACK确认的数据：32~45 字节
- \#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节
- \#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后

在下图，当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。

![640 (6)](D:\notes\面试准备\计算机网络\传输层.assets\640 (6).png)

在下图，当收到之前发送的数据 `32~36` 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则**滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认**，接下来 `52~56` 字节又变成了可用窗口，那么后续也就可以发送 `52~56` 这 5 个字节的数据了。

![640 (7)](D:\notes\面试准备\计算机网络\传输层.assets\640 (7).png)

#### 接收方的滑动窗口

接下来我们看看接收方的窗口，接收窗口相对简单一些，根据处理的情况划分成三个部分：

- \#1 + #2 是已成功接收并确认的数据（等待应用进程读取）；
- \#3 是未收到数据但可以接收的数据；
- \#4 未收到数据并不可以接收的数据；

![640 (8)](D:\notes\面试准备\计算机网络\传输层.assets\640 (8).png)

#### 接收窗口和发送窗口的大小是相等的吗？

并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的。

因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。

### 流量控制

发送方不能无脑的发数据给接收方，要考虑接收方处理能力。

如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。

为了解决这种现象发生，**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**

下面举个栗子，为了简单起见，假设以下场景：

- 客户端是接收方，服务端是发送方
- 假设接收窗口和发送窗口相同，都为 `200`
- 假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响

![640 (9)](D:\notes\面试准备\计算机网络\传输层.assets\640 (9).png)

根据上图的流量控制，说明下每个过程：

1. 客户端向服务端发送请求数据报文。这里要说明下，本次例子是把服务端作为发送方，所以没有画出服务端的接收窗口。
2. 服务端收到请求报文后，发送确认报文和 80 字节的数据，于是可用窗口 `Usable` 减少为 120 字节，同时 `SND.NXT` 指针也向右偏移 80 字节后，指向 321，**这意味着下次发送数据的时候，序列号是 321。**
3. 客户端收到 80 字节数据后，于是接收窗口往右移动 80 字节，`RCV.NXT` 也就指向 321，**这意味着客户端期望的下一个报文的序列号是 321**，接着发送确认报文给服务端。
4. 服务端再次发送了 120 字节数据，于是可用窗口耗尽为 0，服务端无法在继续发送数据。
5. 客户端收到 120 字节的数据后，于是接收窗口往右移动 120 字节，`RCV.NXT` 也就指向 441，接着发送确认报文给服务端。
6. 服务端收到对 80 字节数据的确认报文后，`SND.UNA` 指针往右偏移后指向 321，于是可用窗口 `Usable` 增大到 80。
7. 服务端收到对 120 字节数据的确认报文后，`SND.UNA` 指针往右偏移后指向 441，于是可用窗口 `Usable` 增大到 200。
8. 服务端可以继续发送了，于是发送了 160 字节的数据后，`SND.NXT` 指向 601，于是可用窗口  `Usable` 减少到 40。
9. 客户端收到 160 字节后，接收窗口往右移动了 160 字节，`RCV.NXT` 也就是指向了 601，接着发送确认报文给服务端。
10. 服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 `SND.UNA` 指针偏移了 160 后指向 601，可用窗口 `Usable` 也就增大至了 200。

#### 操作系统缓冲区与滑动窗口的关系

前面的流量控制例子，我们假定了发送窗口和接收窗口是不变的，但是实际上，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会**被操作系统调整**。

当应用进程没办法及时读取缓冲区的内容时，也会对我们的缓冲区造成影响。

#### 窗口关闭

在前面我们都看到了，TCP 通过让接收方指明希望从发送方接收的数据大小（窗口大小）来进行流量控制。

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。**

##### 窗口关闭潜在的危险

接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的。

那么，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，那麻烦就大了。

![640 (14)](D:\notes\面试准备\计算机网络\传输层.assets\640 (14).png)

这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不不采取措施，这种相互等待的过程，会造成了死锁的现象。

##### TCP 是如何解决窗口关闭时，潜在的死锁现象呢？

为了解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**

如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

![640 (15)](D:\notes\面试准备\计算机网络\传输层.assets\640 (15).png)

- 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
- 如果接收窗口不是 0，那么死锁的局面就可以被打破了。

窗口探查探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。

#### 糊涂窗口综合症

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。

到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。

要知道，我们的 `TCP + IP` 头有 `40` 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济了。

就好像一个可以承载 50 人的大巴车，每次来了一两个人，就直接发车。除非家里有矿的大巴司机，才敢这样玩，不然迟早破产。要解决这个问题也不难，大巴司机等乘客数量超过了 25 个，才认定可以发车。

现举个糊涂窗口综合症的栗子，考虑以下场景：

接收方的窗口大小是 360 字节，但接收方由于某些原因陷入困境，假设接收方的应用层读取的能力如下：

- 接收方每接收 3 个字节，应用程序就只能从缓冲区中读取 1 个字节的数据；
- 在下一个发送方的 TCP 段到达之前，应用程序
  还从缓冲区中读取了 40 个额外的字节；

![640 (16)](D:\notes\面试准备\计算机网络\传输层.assets\640 (16).png)

每个过程的窗口大小的变化，在图中都描述的很清楚了，可以发现窗口不断减少了，并且发送的数据都是比较小的了。

所以，糊涂窗口综合症的现象是可以发生在发送方和接收方：

- 接收方可以通告一个小的窗口
- 而发送方可以发送小数据

于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了

- 让接收方不通告小窗口给发送方
- 让发送方避免发送小数据

>**流量控制**
>
>接收端处理数据的速度是有限的。如果发送端发的太快，导致接收端的缓冲区被填满，这个时候如果发送端继续发送，就会造成丢包，进而引起丢包重传等一系列连锁反应。
>因此TCP支持根据接收端的处理能力，来决定发送端的发送速度。
>这个机制就叫做**流量控制(Flow Control)**。
>
>接收端将自己可以接收的缓冲区大小放入TCP首部中的“窗口大小”字段，通过ACK通知发送端；
>窗口大小越大，说明网络的吞吐量越高；
>接收端一旦发现自己的缓冲区快满了，就会将窗口大小设置成一个更小的值通知给发送端；
>发送端接受到这个窗口大小的通知之后，就会减慢自己的发送速度；
>如果接收端缓冲区满了，就会将窗口置为0；
>这时发送方不再发送数据，但是需要定期发送一个窗口探测数据段，让接收端把窗口大小再告诉发送端。
>
>![20180620002859330](D:\notes\面试准备\计算机网络\传输层.assets\20180620002859330.png)
>
>那么接收端如何把窗口大小告诉发送端呢？
>我们的TCP首部中，有一个16位窗口大小字段，就存放了窗口大小的信息；
>16位数字最大表示65536, 那么TCP窗口最大就是65536字节么？
>实际上，TCP首部40字节选项中还包含了一个窗口扩大因子M，实际窗口大小是窗口字段的值左移 M位（左移一位相当于乘以2）。
>
>**接收端窗口如果更新，会向发送端发送一个更新通知，如果这个更新通知在中途丢失了，会导致无法继续通信，所以发送端要定时发送窗口探测包。**

### 拥塞控制

#### 为什么要有拥塞控制呀，不是有流量控制了吗？

前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。

一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。

**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….**

所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。

于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

为了在「发送方」调节所要发送数据的量，定义了一个叫做「**拥塞窗口**」的概念。

#### 什么是拥塞窗口？和发送窗口有什么关系呢？

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

我们在前面提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于引入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。

拥塞窗口 `cwnd` 变化的规则：

- 只要网络中没有出现拥塞，`cwnd` 就会增大；
- 但网络中出现了拥塞，`cwnd` 就减少；

### 那么怎么知道当前网络是否出现了拥塞呢？

其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**

#### 拥塞控制有哪些控制算法？

##### 慢启动

TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？

慢启动的算法记住一个规则就行：**当发送方每收到一个 ACK，就拥塞窗口 cwnd 的大小就会加 1。**

这里假定拥塞窗口 `cwnd` 和发送窗口 `swnd` 相等，下面举个栗子：

- 连接建立完成后，一开始初始化 `cwnd = 1`，表示可以传一个 `MSS` 大小的数据。
- 当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个
- 当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个
- 当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。

![640 (10)](D:\notes\面试准备\计算机网络\传输层.assets\640 (10).png)

可以看出慢启动算法，发包的个数是**指数性的增长**。

> **那慢启动涨到什么时候是个头呢？**
>
> 有一个叫慢启动门限  `ssthresh` （slow start threshold）状态变量。
>
> - 当 `cwnd < ssthresh` 时，使用慢启动算法。
> - 当 `cwnd >= ssthresh` 时，就会使用「拥塞避免算法」。

##### 拥塞避免算法

前面说道，当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。

一般来说 `ssthresh` 的大小是 `65535` 字节。

那么进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**

接上前面的慢启动的栗子，现假定 `ssthresh` 为 `8`：

- 当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 `MSS` 大小的数据，变成了**线性增长。**

![640 (11)](D:\notes\面试准备\计算机网络\传输层.assets\640 (11).png)

所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。

就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

当触发了重传机制，也就进入了「拥塞发生算法」。

##### 拥塞发生

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

- 超时重传
- 快速重传

这两种使用的拥塞发送算法是不同的，接下来分别来说说。

**发生超时重传的拥塞发生算法**

当发生了「超时重传」，则就会使用拥塞发生算法。

这个时候，sshresh 和 cwnd 的值会发生变化：

- `ssthresh` 设为 `cwnd/2`，
- `cwnd` 重置为 `1`

![640 (12)](D:\notes\面试准备\计算机网络\传输层.assets\640 (12).png)

接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。

**发生快速重传的拥塞发生算法**

还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;
- 进入快速恢复算法

##### 快速恢复

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。

正如前面所说，进入快速恢复之前，`cwnd` 和 `ssthresh` 已被更新了：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;

然后，进入快速恢复算法如下：

- 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）
- 重传丢失的数据包
- 如果再收到重复的 ACK，那么 cwnd 增加 1
- 如果收到新数据的 ACK 后，把 cwnd 设置为第⼀步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进⼊拥塞避免状态；![640 (13)](D:\notes\面试准备\计算机网络\传输层.assets\640 (13).png)

也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。

> **拥塞控制**
>
> 虽然TCP有了滑动窗口这个大杀器，能够高效可靠地发送大量数据。
> 但是如果在刚开始就发送大量的数据，仍然可能引发一些问题。
> 因为网络上有很多计算机，可能当前的网络状态已经比较拥堵。
> 在不清楚当前网络状态的情况下，贸然发送大量数据，很有可能雪上加霜。
>
> 因此，TCP引入`慢启动`机制，先发少量的数据，探探路，摸清当前的网络拥堵状态以后，再决定按照多大的速度传输数据。
>
> ![20180620002915553](D:\notes\面试准备\计算机网络\传输层.assets\20180620002915553.png)
>
> 在此引入一个概念`拥塞窗口`。
>
> - 发送开始的时候，定义拥塞窗口大小为1；
> - 每次发送数据包的时候，将拥塞窗口和接收端主机反馈的窗口大小做比较，取较小的值作为实际发送的窗口。
>
> 拥塞控制是防止过多的数据注入网络，使得网络中的路由器或者链路过载。流量控制是点对点的通信量控制，而拥塞控制是全局的网络流量整体性的控制。发送双方都有一个拥塞窗口。接收窗口rwnd，拥塞窗口cwnd。
>
> 1. 慢开始
>    在TCP刚刚连接好并开始发送TCP报文段时，先令拥塞窗口cwnd=1, 即一个最大报文段长度MSS。每收到一个对新报文段的确认后，将cwnd加1, 即增大一个MSS。用这样的方法逐步增大发送方的拥塞窗口cwnd, 可使分组注入网络的速率更加合理。使用慢开始算法后，每经过一个传输轮次（即往返时延RTT), 拥塞窗口cwnd就会加倍，即cwnd的大小指数式增长。这样，慢开始一直把拥塞窗口cwnd增大到一个规定的慢开始门限ssthresh（阈值），然后改用拥塞避免算法。
> 2. 拥塞避免
>    发送端的拥塞窗口cwnd每经过一个往返时延RTT就增加一个MSS的大小，而不是加倍，使cwnd按线性规律缓慢增长（即加法增大），而当出现一次超时（网络拥塞）时，令慢开始门限ssthresh等于当前cwnd的一半（即乘法减小）。
> 3. 快重传
>    快重传技术使用了冗余ACK来检测丢包的发生。同样，冗余ACK也用千网络拥塞的检测（丢了包当然意味着网络可能出现了拥塞）。当发送方连续收到三个重复的ACK报文时，直接重传对方尚未收到的报文段，而不必等待那个报文段设置的重传计时器超时。
> 4. 快恢复
>    发送端收到连续三个冗余ACK (即重复确认）时，执行“乘法减小”算法，把慢开始门限ssthresh设置为出现拥塞时发送方cwnd的一半。与慢开始（慢开始算法将拥塞窗口cwnd设置为1) 的不同之处是，它把cwnd的值设置为慢开始门限ssthresh改变后的数值，然后开始执行拥塞避免算法("加法增大")使拥塞窗口缓慢地线性增大。由于跳过了cwnd从1起始的慢开始过程，所以被称为快恢复。
>
> > 达到什么情况的时候开始减慢增长的速度？
> >
> > 采用慢开始和拥塞避免算法的时候：
> >
> > 1. 一旦cwnd>慢开始门限，就采用拥塞避免算法，减慢增长速度
> > 2. 一旦出现丢包的情况，就重新进行慢开始，减慢增长速度
> >
> > 采用快恢复和快重传算法的时候：
> >
> > 1. 一旦cwnd>慢开始门限，就采用拥塞避免算法，减慢增长速度
> > 2. 一旦发送方连续收到了三个重复确认，就采用拥塞避免算法，减慢增长速度
>
> ![20180620002933354](D:\notes\面试准备\计算机网络\传输层.assets\20180620002933354.png)
>
> 少量的丢包，我们仅仅是触发超时重传；
> 大量的丢包，我们就认为是网络拥塞；
> 当TCP通信开始后，网络吞吐量会逐渐上升；
> 随着网络发生拥堵，吞吐量会立刻下降。
>
> **拥塞控制**，归根结底是TCP协议想尽可能快的把数据传输给对方，但是又要避免给网络造成太大压力的折中方案。
>
> **拥塞控制的标志：**
>
> * 重传`计时器`超时
> * 接收到`三个`重复确认

## 拥塞控制和流量控制的区别

拥塞控制是防止过多的`数据`注入到网络中，可以使网络中的路由器或链路不致过载，是一个`全局性`的过程。流量控制是`点对点`通信量的控制，是一个`端到端`的问题，主要就是权衡`发送端发送数据`的速率，以便`接收端`来得及接收。

## 面向字节流

创建一个TCP的socket，同时在内核中创建一个`发送缓冲区`和一个`接收缓冲区`；
调用`write`时，数据会先写入发送缓冲区中；
如果发送的字节数太大，会被拆分成多个TCP的数据包发出；
如果发送的字节数太小，就会先在缓冲区里等待，等到缓冲区大小差不多了，或者到了其他合适的时机再发送出去；
接收数据的时候，数据也是从网卡驱动程序到达内核的接收缓冲区；
然后应用程序可以调用`read`从接收缓冲区拿数据；
另一方面，TCP的一个连接，既有发送缓冲区，也有接收缓冲区，那么对于这一个连接，既可以读数据，也可以写数据，这个概念叫做`全双工`。

由于缓冲区的存在，所以TCP程序的读和写不需要一一匹配
例如：

- 写100个字节的数据，可以调用一次`write`写100个字节，也可以调用100次`write`，每次写一个字节；
- 读100个字节数据时，也完全不需要考虑写的时候是怎么写的，既可以一次`read`100个字节，也可以一次`read`一个字节，重复100次。

## TCP粘包问题

首先要明确，粘包问题中的“包”，是指`应用层的数据包`。
在TCP的协议头中，没有如同UDP一样的 “报文长度” 字段，但是有一个序号字段。
站在传输层的角度，TCP是一个一个报文传过来的。按照序号排好序放在缓冲区中。
站在应用层的角度，看到的只是一串连续的字节数据。
那么应用程序看到了这一连串的字节数据，就不知道从哪个部分开始到哪个部分是一个完整的应用层数据包。
此时数据之间就没有了边界，就产生了`粘包问题`。

那么如何避免粘包问题呢？
归根结底就是一句话，明确两个包之间的`边界`。

> 对于定长的包
>
> * 保证每次都按固定大小读取即可。
>   例如上面的Request结构，是固定大小的，那么就从缓冲区从头开始按sizeof(Request)依次读取即可。
>
> 对于变长的包
>
> * 可以在数据包的头部，约定一个数据包总长度的字段，从而就知道了包的结束位置。
>   还可以在包和包之间使用明确的分隔符来作为边界(应用层协议，是程序员自己来定的，只要保证分隔符不和正文冲突即可)。

对于UDP协议来说, 是否也存在 “粘包问题” 呢？

> 对于UDP，如果还没有向上层交付数据, UDP的报文长度仍然存在。
> 同时，UDP是一个一个把数据交付给应用层的，就有很明确的数据边界。
> 站在应用层的角度，使用UDP的时候，要么收到完整的UDP报文，要么不收。
> 不会出现收到 “半个” 的情况。

## TCP保证可靠性

1. 序列号、确认应答、超时重传
数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序号会
说明了它下一次需要接收的数据序列号。如果发送发迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认应答丢失，这时发送方在等待一定时间后会进行重传。这个时间一般是$2*RTT(报文段往返时间）+一个偏差值$。
2. 窗口控制与高速重发控制/快速重传（重复确认应答）
TCP 会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。
使用窗口控制，如果数据段 1001-2000 丢失，后面数据每次传输，确认应答都会不停地发送序号为 1001 的应答，表示我要接收 1001 开始的数据，发送端如果收到 3 次相同应答，就会立刻进行重发；但还有种情况有可能是数据都收到了，但是有的应答丢失了，这种情况不会进行重发，因为发送端知道，如果是数据段丢失，接收端不会放过它的，会疯狂向它提醒......
3. 拥塞控制

# UDP协议

## 概述

UDP的（User Datagram Protocol，用户数据报协议），UDP是**传输层**的协议，功能即为在IP的数据报服务之上增加了最基本的服务：**复用**和**分用**以及**差错检测**。

UDP提供**不可靠**服务，具有TCP所没有的**优势**：

* UDP**无连接**，时间上**不存在建立连接需要的时延**。空间上，TCP需要在端系统中**维护连接**状态，需要一定的开销。此连接装入包括接收和发送缓存，拥塞控制参数和序号与确认号的参数。UCP不维护连接状态，也不跟踪这些参数，开销小。空间和时间上都具有优势。

  举个例子：

  DNS如果运行在TCP之上而不是UDP，那么DNS的速度将会慢很多。
  HTTP使用TCP而不是UDP，是因为对于基于文本数据的Web网页来说，**可靠性**很重要。
  同一种专用应用服务器在支持UDP时，一定能支持更多的活动客户机。

* 分组首部开销小，TCP首部20字节，UDP首部8字节。

* **UDP没有拥塞控制**，因此网络出现的拥塞不会使源主机的发送速率降低。某些实时应用要求以稳定的速度发送，**能容忍一些数据的丢失，但是不能允许有较大的时延**（比如实时视频，直播等）。UDP正好符合这种要求。

* UDP**提供尽最大努力的交付**，不保证可靠交付。所有维护传输可靠性的工作需要用户在**应用层**来完成。没有TCP的确认机制、重传机制。如果因为网络原因没有传送到对端，UDP也不会给应用层返回错误信息。

* UDP是**面向报文**的，对应用层交下来的报文，添加首部后直接向下交付为IP层，既不合并，也不拆分，保留这些报文的边界。对IP层交上来UDP用户数据报，在去除首部后就原封不动地交付给上层应用进程，报文不可分割，是UDP数据报处理的最小单位。
  正是因为这样，UDP显得不够灵活，不能控制读写数据的次数和数量。比如我们要发送100个字节的报文，我们调用一次sendto函数就会发送100字节，对端也需要用recvfrom函数一次性接收100字节，不能使用循环每次获取10个字节，获取十次这样的做法。

* UDP**常用一次性传输比较少量数据的网络应用**，如DNS、SNMP等，因为对于这些应用，若是采用TCP，为连接的创建，维护和拆除带来不小的开销。UDP也常用于多媒体应用（如IP电话，实时视频会议，流媒体等）数据的可靠传输对他们而言并不重要，TCP的拥塞控制会使他们有较大的延迟，也是不可容忍的。

## UDP数据报

UDP数据报分为**首部**和**用户数据部分**，整个UDP数据报作为IP数据报的数据部分封装在IP数据报中，UDP数据报文结构如图所示：

![20181226160325166](D:\notes\面试准备\计算机网络\传输层.assets\20181226160325166.png)

UDP首部有8个字节，由4个字段构成，每个字段都是两个字节：
1.**源端口**： 源端口号，需要对方回信时选用，不需要时全部置0。
2.**目的端口**：目的端口号，在终点交付报文的时候需要用到。
3.**长度**：UDP的数据报的长度（包括首部和数据）其最小值为8（只有首部）。
4.**校验和**：检测UDP数据报在传输中是否有错，有错则丢弃。该字段是可选的，当源主机不想计算校验和，则直接令该字段全为0。
当传输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交给应用进程。
如果接收方UDP发现收到的报文中的目的端口号不正确（不存在对应端口号的应用进程0），就丢弃该报文，并由ICMP发送“端口不可达”差错报文给对方。

## UDP校验

### 伪首部

在计算校验和的时候，需要在UDP数据报之前增加**12字节的伪首部**，伪首部并不是UDP真正的首部。只是在计算校验和，临时添加在UDP数据报的前面，得到一个临时的UDP数据报。校验和就是按照这个临时的UDP数据报计算的。伪首部既不向下传送也不向上递交，而**仅仅是为了计算校验和**。这样的校验和，既**检查了UDP数据报，又对IP数据报的源IP地址和目的IP地址进行了检验。**

![2396023668-58b7cb4e4a92b_articlex](D:\notes\面试准备\计算机网络\传输层.assets\2396023668-58b7cb4e4a92b_articlex.png)

**伪首部各个字段意义**：

1. 第一字段，源IP地址
2. 第二字段，目的IP地址
3. 第三字段，字段全0
4. 第四字段，IP首部中的协议字段的值，对于UDP，此字段值为17
5. 第五字段，UDP用户数据报的长度

### 检验和计算方法

UDP校验和的计算方法和IP数据报首部校验和的计算方法相似，都使用二进制反码运算求和再取反，但不同的是：IP数据报的校验和只检验IP数据报和首部，但UDP的校验和是把首部和数据部分一起校验。

发送方，首先是把**全零放入校验和字段**并且添加**伪首部**，然后把UDP数据报看成是由许多16位的子串连接起来，若UDP数据报的数据部分不是偶数个字节，则要在数据部分末尾增加一个全零字节（此字节不发送），接下来就按照二进制反码计算出这些16位字的和。将此和的二进制反码写入校验和字段。在接收方，把收到得UDP数据报加上伪首部（如果不为偶数个字节，还需要补上全零字节）后，按二进制反码计算出这些16位字的和。**当无差错时其结果全为1**。否则就表明有差错出现，接收方应该丢弃这个UDP数据报。

![20181226170949756](D:\notes\面试准备\计算机网络\传输层.assets\20181226170949756.png)

如果UDP校验和校验出UDP数据报是错误的，可以丢弃，也可以交付上层，但是要附上错误报告，告诉上层这是错误的数据报。
通过伪首部，不仅可以检查源端口号，目的端口号和UDP用户数据报的数据部分，还可以检查IP数据报的源IP地址和目的地址。
这种差错检验的检错能力不强，但是简单，速度快。

# ==TCP和UDP的区别==

1. 连接
    TCP 是面向连接的传输层协议，即传输数据之前必须先建立好连接。
    UDP 无连接。

2. 服务对象
    TCP 是点对点的两点间服务，即一条 TCP 连接只能有两个端点；
    UDP 支持一对一，一对多，多对一，多对多的交互通信。

3. 可靠性
    TCP 是可靠交付：无差错，不丢失，不重复，按序到达。
    UDP 是尽最大努力交付，不保证可靠交付。

4. 拥塞控制，流量控制
    TCP 有拥塞控制和流量控制保证数据传输的安全性。
    UDP 没有拥塞控制，网络拥塞不会影响源主机的发送效率。

5. 报文长度
    TCP 是动态报文长度，即 TCP 报文长度是根据接收方的窗口大小和当前网络拥塞情况决定的。
    UDP 面向报文，不合并，不拆分，保留上面传下来报文的边界。

6. 首部开销
    TCP ⾸部⻓度较⻓，会有⼀定的开销，⾸部在没有使⽤「选项」字段时是 20 个字节，如果使⽤ 了「选项」字段则会变⻓的。
    UDP ⾸部只有 8 个字节，并且是固定不变的，开销较⼩。

7. 传输方式

    TCP 是流式传输，没有边界，但保证顺序和可靠。 

    UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序。

> **为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？**
>
> 原因是 TCP 有**可变长**的「选项」字段，而 UDP 头部长度则是**不会变化**的，无需多一个字段去记录 UDP 的首部长度。
>
> **为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？**
>
> 先说说 TCP 是如何计算负载数据长度：
>
> $TCP数据的长度=IP总长度-IP首部长度-TCP首部长度$
>
> 其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。
>
> 大家这时就奇怪了问：“ UDP 也是基于 IP 层的呀，那 UDP 的数据长度也可以通过这个公式计算呀？为何还要有「包长度」呢？”
>
> 这么一问，确实感觉 UDP 「包长度」是冗余的。
>
> 因为为了网络设备硬件设计和处理方便，首部长度需要是 `4`字节的整数倍。
>
> 如果去掉 UDP 「包长度」字段，那 UDP 首部长度就不是 `4` 字节的整数倍了，所以小林觉得这可能是为了补全 UDP 首部长度是 `4` 字节的整数倍，才补充了「包长度」字段。

# TCP和UDP的适用场景
由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输
- `HTTP` / `HTTPS`

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等
- 视频、音频等多媒体通信
- 广播通信

