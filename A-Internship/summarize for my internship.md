# What I Have Done During My Internship

## 字节跳动实习

### 等级后置功能迁移至现有的完备的用户触达服务。
用户触达服务的功能总体概况就是提醒用户上课、提醒用户支付。所涉及的服务模块分为：management、trigger、dispatcher、executer、user selection这五大模块。

发送短信涉及三要素： 短信内容（management）、短信发送的时间（management、trigger、dispatcher）、短信发送的对象（user selection）。

management模块：    主要负责管理配置的课程，包括课程的基本信息、什么时候开课、什么时候发送短信、备注信息等，该模块主要与mysql数据库交互，主要负责存储，其次是将首次需要触发的定时任务放入eventbus1（底层实现使用了rocketmq、kafka等）。

trigger模块：       接收来自订单中心的消息队列（eventbus2）推送的订单信息，将“无效的订单消息”过滤后判断，将需要触发的即时任务放入eventbus1。

dispatcher模块：    接收来自eventbus1中的任务消息，将需要触发的短信消息去user selection模块中圈选匹配的人群，最后将打包好的短信交给executer模块执行。（对于即时任务立即触发，对于定时任务反复出队进队，可以考虑优化。）

user selection模块：圈选所要触达的人群，给特定的人发送触达短信。

executer模块：      执行发送短信步骤。

等级后置：当用户购买课程后未选择课程等级时，经过5分钟给用户一个短信提醒，因为课程等级关乎用户的上课内容必须由用户选择。

此次迁移的关键点在于如何trigger模块中辨别该订单消息属于等级后置、如何在user selection模块中辨别该订单是否已经选择等级，在理解订单流的基础上，需要对上述五个模块都有小部分修改。

订单流：订单创建、订单未支付、订单已支付、订单已退款、订单已失效...

我的感受：触达服务的整体规划让我感到眼前一亮，其组织结构、各模块之间的联系与结合非常得清晰易懂，这五个服务有很多可以值得借鉴学习的地方，该服务对新人的学习成长很有帮助。这个需求也是我第一次接触前端同学、PM同学，在把所有功能修改完成的时候，我才去找PM审核，结果在PM理解上与我的想法存在分歧，导致了我的“第一次外交失败”，经历了这一次的事件，职场团队意识在我脑海中渐渐萌芽，是的，一味得埋头比不上多与他人交流，更何况我只是一个初入职场的实习生。而之后与另一个PM的沟通则比较顺利，积极得表达对别人的肯定，也积极得表达我不同的想法，在这种基础上别人也更容易接受。

### EV老班课迁移
班课系统由老班课服务升级成了新班课服务，我们的服务调用了老班课服务，由此需要将其迁移至新班课服务。该需求比较简单。

### 国内hive数据同步至海外
首先国内环境与国外环境不通，无法通过简单的数据拷贝实现，调研了多种方案，最终采用了两种方案实践，其中最先实践的方案1存在数据不一致的问题无法解决，后继续调研发现通过hdfs文件系统拷贝的方式可以解决方案1存在的问题。

该需求耗时较久，断断续续得去实现，主要存在的问题还是个人对hive、hdfs、kafka、mirror、rocketmq等一些基础组件不熟悉，在实践过程中存在大量的猜测验证想法，这在极大程度上造成了时间的耗费，另外该需求需要审批大量工单以及公司hive表T+1可见性的限制，使得我不能集中时间去解决这个需求。

我的感受：基础知识还不够扎实，需要在实习结束后对常用的基础组件做一个强化学习。

### 出货量服务
需求背景：
海外厂商App预装手机需要一个记录以往数个月的出货记录，以及对未来一定时间的出货量进行预估，以达到更好的投放效果。目标是平台化，方便记录查看的同时也容易上传和导入历史数据。

数据库设计：
出货量平台在设计上主要考虑到不同的app预装作为一个维度，各个月份作为另一个维度，所以设计成了主表和子表的层次。主表的内容大致为出货厂商app的一些信息以及总的出货统计量等；子表的内容为对应出货厂商app每一个月的出货量。

系统设计：
1.每一次子表的更新是必涉及主表对应统计量的更新，所以采用事务的特性。
2.上传每月出货量信息时可能非常庞大，上传记录最高可达几万条，一次性上传耗时比较大，考虑到月份数量本身不多以及后长传的数据会覆盖旧数据，因此对上传数据先做好预处理再对子表采用go协程进行更新，加快速度。3.每个月初需要自动生成默认的出货量记录，采用faas实现。

我的感受：
起初该需求是两个人来一起完成的，不巧的是同事中途被派出去做别的项目了，因此这算是第一次我一个人来完成一个新需求，有些压力，好在需求比较简单，经过一个月不到的时间完成了上线。在这个过程中也遇到一个小问题，当大量的数据进行上传时，由于采用了协程，但是子表的唯一键不小心分析错误给删了，导致了上传数据时偶发死锁问题，经过排查学习，发现mysql在rc隔离级别下更新记录是锁行，且存在相互等待的情况，由此得到了两个解决方案：1.把子表加上唯一键。2.仅仅将需上传的数据进行预处理，保证处理结果不会造成死锁。最终选择了方案二，这既解决了死锁问题，又大大得缩减了上传更新的数据量，大大提升了上传速度。该需求虽然简单，但是作为第一个我参与的平台设计还是略显稚嫩，当然也学到了一些知识，学到了在公司要完成一个需求该经历的一些基本步骤，还是比较满意的。

### 媒体列表服务
需求背景：
海外广告投放涉及了大量的媒体，每一个媒体下面有其特有的app和账户，其都有各自的特点，其中大媒体就有20几个，还有上百个小媒体，而这些媒体的接入的差异性显著，特别是对于一个新接触的同学，只能通过阅读官方文档来逐个进行学习了解，其耗费的时间人力将非常得大。况且app之间和账户之间的差异性也非常得大，很难用统一的字段来维护，举个简单的例子（Google平台下的账户唯一键为账户名称、账户id、账户密码；Facebook平台下的账户唯一键为邮箱、Account_key）。所以将这些媒体及其下的app和账户进行一个共性的挖掘，做一个统一的管理非常有必要，废弃原有的配置文件转而实现平台化，配以可自定义配置的接入文档doc，加上账户配置成功之后自动触发历史数据的抓取回溯功能，使得人效方面进一步提升。

数据库设计：思路很清晰，根据展示效果，将表设计为两个层级：媒体平台部分、(媒体平台下的app、媒体平台下的账户)。应数据分析同学的需要，将媒体平台部分的渠道独立差分为一个表。“海外媒体平台表”包含媒体的基本信息、媒体已经建设的能力、渠道版本号、支持的操作系统、接入文档；“海外媒体产品配置表”包含属于哪个媒体平台、产品配置元信息（json字符串）;“海外媒体授权配置表”包含属于哪个媒体平台、账户配置元信息（json字符串）。之所以把产品配置元信息和账户配置元信息存储为json格式是出于各个媒体差异性考虑，在设计过程中只知道20几个大媒体的元信息，而其他100多个小媒体还未确定元信息，因此出于可拓展性考虑，存储为json字符串方便后续的拓展。

系统设计：
1.两个层级界面，层级一为媒体列表主界面，展示各大媒体平台的基本信息，包括接入文档、平台能力、操作系统等；层级二分别为媒体平台下的产品配置界面和账户授权配置界面。
2.添加或更新媒体平台时涉及到渠道版本的更新，涉及多个表，所以使用事务保证操作的一致性。
3.每一次的新增、修改产品配置或者账户授权配置，都会使用http的post请求修改负责为抓取任务提供账号信息的配置文件。（该配置文件也是json格式，但是由于不同的媒体平台字段不一致，导致唯一键必须确定，这是在开发前未考虑到的，在开发过程中逐步跟PM确认了这个事情。）
4.每一次新增、修改账户授权配置后，若涉及到回溯时间则会触发抓取任务抓取历史数据。这里的抓取任务是通过一个python服务实现的，只需要一个http调用即可。账户数据抓取状态分为待回溯、回溯中、已回溯三个状态。
5.那抓取任务何时触发呢？固定每天凌晨0点触发当天处于“未抓取”状态的媒体账户进行抓取，每一次抓取都有一个jobid可以获取到。
6.那如何判断抓取任务是否成功了呢？通过上面这个jobid可以再发送一个http请求获取任务状态，在每日凌晨触发抓取任务之前去判断前一天的那一批任务状态。
7.BUG？一开始设计的账户数据抓取状态只有两个，分别为待回溯、已回溯。在这种情况下如果数据已经在回溯中，即任务触发了抓取任务，但是还未等到第二天检测抓取任务状态执行，在此期间如果修改了回溯时间，且第二天检测到抓取任务成功，那么就会造成抓取的数据与期望的数据不一致的情况，因此需要将账户数据抓取状态增加一个回溯中状态。
8.采用两个faas服务实现对配置文件的更新、抓取任务触发及检测。
9.其中抓取任务触发是跨区域调用http请求，失败的风险比较高，所以将所有成功的失败的jobid存储到redis中，方便后续排查。与此同时，设置了任务失败的报警机制，有效规避风险。
10.媒体平台层级有一个字段“在投app”，需要去一张hive表中查询该媒体平台下近一个月是否有在投放的app，粗略查询了一下近一个月的在投app有3亿多条数据，而公司的服务只能支持100w条数据的返回，数据量过大怎么办呢？考虑到媒体平台数量100+，每个平台下的app又不会太多，因此对hsql进行一个按照媒体平台和appid的分组成功将返回的数据量降低到1000+。而每次对如此庞大的数据量进行查询耗时接近5分钟，优化是将查询结果缓存至redis中。此服务也设计成了faas服务。

使用的技术栈：
mysql、redis、http调用、faas、rpc调用、

未来可改进方面：

我的感受：
作为基础建设，我们需要考虑整个团队内部的建设，包括一些基础性的东西的抽象，挖掘共性，层次等，然后实现平台化，与此同时，我们也应该想到内部服务之间、平台之间能否产生一些联动，当然自动化触发等都是一个比较好的思路（可以大大节省人力），在以后的实习已经入职之后首先要想的就是了解整个团队内部的服务之间的关系，以此作为点面的突破口迅速融入一个团队。同时我们也应该想到给别的团队提供一个怎么样的能力，包括数据方面、服务方面，如何更好得提供服务。



### 字节实习经历简介

之前在字节国际化增长团队实习了六个月，我所负责的主要是服务完善整合以及平台化工作，我完成了两个服务的上线，以及两个服务的迁移。

**其中出货量服务**，数据库表的设计、CRUD、上万条记录上传的优化都是由我完成的，在此期间发现了一个并发上传数据库死锁问题，最后明确问题出在rc隔离级别且失去索引的情况下，造成全表扫描两个事务相互等待的情况，最后对数据预处理解决了该问题。

**媒体列表服务**，是由我完全独立开发完成的，海外广告投放涉及到了大量的媒体，媒体下面有各种app，他们在这些app里面投广告。这个服务是为了对各大媒体及其下的app和账户进行管理，方便不同媒体平台的接入，简单来说就是一个管理系统，相比于普通的管理系统，我这个服务还需要提供不同媒体数据（如广告投放数据）的自动抓取工作。整个平台的后端架构是一个http管理服务、一个rpc主服务、三个faas服务。此服务的难点包括：1.不同媒体账户、不同app的唯一键由多个不同的字段来标识。2.当配置了媒体账户之后还要自动触发抓取任务，这个抓取任务是另一个python服务提供的，不同账户调用的python服务接口是不同的。3.“在投app”字段的值要从3亿条数据的hive表中读取。

**针对第一个问题**：

- 不可能是说把所有的媒体特殊字段都在mysql表里面增加一个列，而且项目开发初期，我们只知道现有的20几个平台的数据格式，根本不知道其他100多个平台的字段是怎么样子的，所以这就涉及到一个可扩展性的问题。最终我是把这些字段全部抽象成了一个json字符串存储于mysql，这样的好处就可以满足我们可拓展的要求，未来要新增一个媒体的话，不需要修改数据库，只需要修改相应部分的几行代码即可。
- 这些媒体的字段，老服务是存在一个配置文件中，现在我这个服务就是做了一个平台化的事情，在实际的应用过程中，不可能是老服务的配置文件直接废弃了，这肯定是一个逐步迁移的过程，这就需要考虑在现在的服务上配置了媒体，也需要同步得去更新配置文件，然后这里有一个去重的过程。那如何判重，肯定需要一些特殊的字段，也就是唯一键，但原有的配置文件是手工维护的，根本就没有什么唯一键，这个问题后面我去跟PM逐步沟通，确认了这个问题，也写进了开发文档。当然如果在我的服务平台上新增媒体就不需要考虑重复的问题，因为代码里已经有逻辑限制了。

**针对第二个问题**：

- 这个数据抓取任务是通过http调用一个python服务，PM原本的要求是自定义抓取多少天的数据，在开发过程中，我发现抓取任务这个python服务也存在这一些不稳定性，有一些任务可能参数填写得不对，他会抓取失败。然后我就想，我们能不能让前端的用户也能感知到这个数据抓取是否成功，目的还是提升团队的效率、节省人力嘛，这样的话用户能有一个更直观的了解，同时配置报警，尽早得通知研发。这是我当时的想法，然后这个数据抓取任务并不是一下子就完成的，他需要10分钟左右的时间才能给一个返回结果。这是一个异步的过程，于是我也设计成了faas服务，执行任务采用redis缓存了所有的jobid，然后每天执行任务之前去check前一天的抓取任务的状态，如果任务失败，除了会触发报警之外，还会重新放入待抓取列表等待再一次触发执行。

**针对第三个问题**：

- “近30天的在投app”读取，首先数据量非常得大，有三亿多条数据，查询比较慢，多次测试平均下来需要10分钟左右。针对数据量大和查询慢，我就使用了redis缓存预热的方式，先对媒体和appid进行group by得到1000多条数据，然后把媒体作为key，appid的list作为value，过期时间设置成一天多一点，然后这也设计成了faas服务，每天凌晨去更新一下数据。

**服务拆分：**

在开发的中期，发现获取媒体列表，一部分需要提供给前端页面做展示用，同时还会有其他服务需要用，这算内部服务的调用，而服务间的调用最好用rpc，然后前端页面调用又必须使用http，所以考虑拆分成两个服务，一个rpc服务作为核心，然后http服务作为使用放调用rpc，同时被前端调用。

然后为什么内部服务最好用rpc，是因为rpc调用1.代码更加简单，req和resp可以控制schema，比http解析body更好。 2.公司内部框架封装了很多功能，比如logid，流量控制，自动日志，流量追踪，比http会多一些 3.使用thrift序列化反序列化，比http一般的json更高效（当然http也不一定就用json）



## 智臾科技实习

### Python Parser

本项目实质上是一个解析器，一般的解析器都是针对一种语言的，而我们支持了 Python 和 DDB 两种语言，满足大多数金融用户的需求。其目的是将 Python、DDB 语言转化为 DDB 内部的数据结构和执行单元。
其主要的模块分为 Tokenizer 将 script 转化为 Token 序列；Parser 根据语法规则将 Token 序列解析为一棵抽象语法树 AST；Interpreter 遍历语法树生成内部可执行的数据结构。采用**visitor模式**，因为我们要在语法树上做很多不同的操作，比如输出语法树、符号表的生成、转化为ddb内部数据结构，这样一来，把node结点与操作分离开来，同时也支持更方便得拓展对语法树的访问。
在 Parser 和 Interpreter 之间，我们需要一个 Symbol Table，这就是符号表，其主要作用是辨别各个变量名、函数名的作用域，比如一个变量是 local、global、free、cell variable。在本项目中符号表主要为函数的嵌套调用提供帮助：
由于 DDB 是不支持函数嵌套调用的，一个函数只能知道其内部的变量，那么如何让函数使用外部变量呢？就是传参，我们需要根据符号表来知道这个变量是否需要传递到函数的参数中去，这些变量对应了 free variable、cell variable。

本项目的性能优化：
使用 gprof 工具查看所有函数调用次数和时间，分析隐藏的可以优化的点：

1. 由于语法规则的复杂性，很多小函数被频繁得调用，造成了巨大的时间开销。分析找到了被重复解析的函数，采用记忆化的方式以空间换时间将时间减少了1倍。
2. 小改动：存在大量的小字符串匹配函数，而这些字符串是标准的关键字，多维护一个TokenType字段，将字符串比较改为数字比较。
3. 小改动：某一些函数的值拷贝，能用引用代替就代替之。
4. 参考Pratt，根据优先级去解析表达式，可以节省很多层不必要的rule的函数调用，这个效果也是明显的，对于特定的表达式计算可以提升2倍以上。

   （原本在表达式解析的过程中会递归调用大量的规则函数，这些函数最终都是去找一个atom，这就造成了很多不必要的函数调用。然后查阅了一些资料，发现Pratt有很大的优势，它考虑了表达式符号的优先级，根据优先级可以确定表达式树的叶子结点，就不需要根据繁杂的语法规则去解析表达式了）




## 自我介绍
面试官好，
我叫沈鑫杰，现就读于浙江大学软件学院，现在是找暑期实习，时间方面如果录取的话会提前入职。
本科是浙江农林大学，本科期间参加过ACM，最好成绩是EC-FINAL的铜牌，也拿过天梯赛的团队金奖。还担任过班长和社团的一些职务，有一定的组织能力。本科期间跟着导师做过一个作业代码查重的小项目，研究生入学前在导师的公司实习了两个月，去年上半年在北京字节跳动有限公司实习了6个月，所在的部门是国际化增长，主要做的是面向内部的服务，目前在智臾科技实习了一个多月，做的是python语言的解释器，这是我的基本情况。

  # 孟哥提到的重点
  http要知道的，发了我一个http协议.pdf
  项目方面提及的问题，得有一个清晰的表述，需要自己模拟写一遍。如果让你讲项目，可以从背景、数据的处理及流向方面展开。
  redis基础知识
  消息中间件，常见的几个要知道一些，包括他们的区别，最好能知道字节的与常见的区别。加分项。
  腾讯投ieg和wx，阿里投aliyun，挂了再被捞好了。腾讯在官网投就行。
  杭州就阿里字节网易滴滴。